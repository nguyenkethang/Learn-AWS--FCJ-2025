---
title: "Event 3"
date: 2025-11-15
weight: 3
chapter: false
pre: " <b> 4.3. </b> "
---

# 🤖 AI/ML/GenAI on AWS Workshop

### 🎯 Workshop Goals

- Explore the current AI/ML landscape and AWS service offerings in the Vietnamese market
- Gain hands-on experience with end-to-end machine learning through Amazon SageMaker
- Discover the power of Generative AI using Amazon Bedrock
- Develop skills in prompt engineering and RAG (Retrieval-Augmented Generation) methodologies
- Create real-world AI/ML applications leveraging AWS technologies

### 📍 Event Details

- **Location**: 26th Floor, Bitexco Financial Tower, 2 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City 
- **Date & Time**: 8:30 AM – 12:00 PM, Saturday, November 15, 2025

### 👨‍🏫 Speakers & Coordinators

**Instructors:**

- **Lam Tuan Kiet** – Senior DevOps Engineer, FPT Software – Amazon SageMaker and ML Services Overview
- **Dinh Le Hoang Anh** – Cloud Engineer Trainee, FCAJ Swinburne University of Technology – Amazon Bedrock and AWS AI/ML Services
- **Danh Hoang Hieu Nghi** – Fresher AI Engineer, Renova Cloud – Amazon Bedrock Agent Core, live demonstrations and hands-on guidance

**Coordinators:**

- **AWS Vietnam Community Team**
- **FCJ Program Leaders**

### 📋 Program Schedule

#### ⏰ 8:30 – 9:00 AM: Opening & Getting Started

- Check-in and participant networking
- Introduction to workshop goals and expected outcomes
- Ice-breaker activities to build connections
- Current state of AI/ML adoption in Vietnam

#### ⏰ 9:00 – 10:30 AM: Exploring AWS AI/ML Ecosystem

**🔬 Amazon SageMaker – Complete ML Solution**

- **Data Processing and Annotation**:
  - Leveraging Data Wrangler for data cleaning and transformation
  - Ground Truth tools for accurate data labeling
  - Feature Store for efficient feature storage and reuse
- **Training, Optimization, and Deployment**:
  - Pre-built algorithms and customizable training code
  - Automated hyperparameter optimization for model performance
  - Flexible deployment: real-time inference, batch processing, or serverless
  - A/B testing capabilities and multi-model management
- **Robust MLOps Integration**:

  - Pipelines for automating the entire ML workflow
  - Registry for model versioning and governance
  - Monitor for tracking quality and detecting data drift
  - Seamless integration with CI/CD tooling

- **Live Demo**: Hands-on with SageMaker Studio
  - Setting up a notebook environment
  - End-to-end model training process
  - Deploying and testing endpoints in practice

#### ☕ 10:30 – 10:45 AM: Coffee Break

- Networking and refreshments
- Q&A with AWS experts

#### ⏰ 10:45 AM – 12:00 PM: Generative AI and AWS AI Service Portfolio

**🛠️ AWS AI/ML Service Suite**

- **Amazon Rekognition**: Intelligent image and video analysis
- **Amazon Translate**: Multi-language translation powered by neural networks
- **Amazon Textract**: Automated document data extraction
- **Amazon Transcribe**: Speech-to-text conversion service
- **Amazon Polly**: Natural voice synthesis from text
- **Amazon Comprehend**: Text analysis and sentiment detection
- **Amazon Kendra**: ML-driven intelligent search
- **Amazon Lookout**: Operational anomaly detection
- **Amazon Personalize**: Personalized recommendation systems

**🧠 Foundation Models: Claude, Llama, Titan**

- **Model Analysis & Selection Criteria**:
  - Claude (Anthropic): Excels at conversation and complex logic
  - Llama (Meta): Open-source with high customization potential
  - Titan (Amazon): Cost-optimized with deep AWS integration
  - Guidelines for matching models to specific scenarios

**✍️ The Art of Prompt Engineering**

- **Proven Prompting Methods**:
  - Providing specific instructions with proper context
  - Using few-shot learning through examples
  - Applying Chain-of-Thought for complex problem-solving
  - Defining roles and personas for AI responses
- **Advanced Approaches**:
  - Managing temperature and token limits
  - Understanding system vs user prompts
  - Creating reusable prompt templates

**🔗 Retrieval-Augmented Generation (RAG)**

- **RAG System Design**:
  - Vector database foundations and embedding representations
  - Semantic search for intelligent document retrieval
  - Dynamic context injection into prompts
- **Knowledge Source Integration**:
  - Bedrock Knowledge Bases as the foundation
  - **Amazon S3** for document and knowledge storage
  - Multi-source connectivity (S3, databases, external APIs)
  - Document chunking approaches and metadata organization
  - Security through S3 policies and access controls

**🤖 Amazon Bedrock Agent Core**

- **Agent Orchestration**:
  - Bedrock Agent Core for building autonomous AI agents
  - Multi-step reasoning and task planning
  - Action groups and API integrations
  - Memory and conversation state management
- **Tool Integrations**:
  - **AWS Lambda** functions as tools for custom business logic
  - Lambda integration for real-time data processing
  - External API connections via Lambda
  - Database queries and data retrieval through Lambda
  - Serverless architecture benefits with Lambda + Bedrock

**🛡️ Guardrails: Safety and Content Filtering**

- Content moderation and toxicity detection
- PII (Personally Identifiable Information) filtering
- Topic-based filtering and denied topics
- Custom guardrails for business requirements

**💻 Live Demo: Building a Generative AI Chatbot using Bedrock**

- Setting up Bedrock foundation model access
- Creating a simple chatbot with prompt engineering
- Implementing RAG with Knowledge Bases
- Adding guardrails for safe responses
- Testing and iterating on the chatbot

### 💡 Key Takeaways

#### 🔬 Amazon SageMaker Capabilities

- **End-to-End ML Platform**: SageMaker provides all tools needed from data preparation to model deployment
- **MLOps Integration**: Built-in capabilities for automating and monitoring ML workflows
- **Scalability**: Easily scale from experimentation to production workloads
- **Cost Optimization**: Pay-as-you-go pricing with options for spot instances and serverless inference

#### 🤖 Generative AI with Bedrock

- **Model Diversity**: Access to multiple foundation models without managing infrastructure
- **Prompt Engineering**: Critical skill for getting quality outputs from LLMs
- **RAG Architecture**: Combines the power of LLMs with your proprietary data
- **Safety First**: Guardrails ensure responsible AI deployment
- **Agent Capabilities**: Enable complex, multi-step AI workflows

#### 🚀 Practical Implementation

- **Start with Use Cases**: Identify specific business problems AI/ML can solve
- **Experiment and Iterate**: Use SageMaker Studio for rapid prototyping
- **Leverage Pre-built Models**: Start with foundation models before custom training
- **Implement Guardrails**: Always prioritize safety and compliance
- **Monitor and Optimize**: Continuously track model performance and costs

### 💼 Applying to Work

- **Explore SageMaker**: Start with SageMaker Studio free tier to experiment with ML workflows
- **Build RAG Applications**: Implement knowledge base integration for domain-specific chatbots
- **Practice Prompt Engineering**: Develop effective prompting strategies for your use cases
- **Implement MLOps**: Automate ML pipelines using SageMaker Pipelines
- **Deploy Bedrock Agents**: Create intelligent agents for automating business processes
- **Ensure Compliance**: Use Bedrock Guardrails to meet regulatory requirements
- **Share Knowledge**: Document learnings and best practices with your team

### ✨ Workshop Highlights

The **"AI/ML/GenAI on AWS Workshop"** held at AWS Vietnam Office delivered an engaging, hands-on learning journey into modern AI/ML technologies. Notable highlights included:

#### 👨‍🏫 Expert Knowledge Sharing

- **Solutions Architects** shared deep insights into SageMaker's comprehensive ML capabilities
- **GenAI Specialists** showcased real-world applications of Bedrock and foundation models
- Case studies demonstrated how Vietnamese enterprises are adopting AWS AI/ML services
- Detailed consultation on selecting appropriate technologies for different business scenarios

#### 💻 Live Demonstrations and Practice

- Observed the complete **SageMaker Studio** workflow from data prep to production
- Experienced how **Amazon Bedrock** accelerates GenAI app development without infrastructure overhead
- Practiced **prompt engineering** techniques with immediate impact on output quality
- Investigated **RAG architecture** for building knowledge-enhanced AI solutions
- Learned how **Bedrock Agents** automate multi-step processes

#### 📊 Market Insights

- Understood **AI/ML adoption patterns and trends** emerging in Vietnam
- Clarified **distinctions between traditional ML and Generative AI** - when to use each
- Learned the boundaries between **SageMaker and Bedrock** for optimal tool selection
- Recognized the critical role of **MLOps** in scaling ML systems

#### 🤝 Building Professional Networks

- Met developers and data scientists passionate about AWS AI/ML
- Shared experiences on implementation challenges and practical solutions
- Established connections with AWS experts for long-term support
- Became part of the AWS AI/ML community for ongoing knowledge exchange

#### 📚 Key Lessons Learned

- **Foundation models** make powerful AI accessible without massive investment
- **Prompt engineering** is the determining factor in GenAI application quality
- **RAG architecture** addresses the challenge of LLMs lacking specialized knowledge
- **Guardrails** are indispensable for safe and compliant AI deployment
- **SageMaker** offers an all-in-one platform accelerating the entire ML lifecycle

#### 🎯 Action Plan

- Start with **SageMaker Studio** free tier to familiarize with the platform
- Develop a **RAG application** prototype using Bedrock Knowledge Bases
- Train on **prompt engineering** across various foundation models
- Investigate **Bedrock Agents** for workflow automation
- Apply **MLOps practices** through SageMaker Pipelines
- Stay connected with the **AWS AI/ML community** for continuous learning

#### 📸 Some Event Photos

![Workshop presentation](images/image1.jpg)
<hr>

![Speaker demonstrating AWS services](images/image2.jpg)
<hr>

![Technical demonstration](images/image3.jpg)
<hr>

![Hands-on practice session](images/image4.jpg)
<hr>

![Participants engaged in learning](images/image5.jpg)
<hr>

![Interactive Q&A session](images/image6.jpg)
<hr>

![Networking and collaboration](images/image7.jpg)
<hr>

![Workshop atmosphere](images/image8.jpg)
<hr>

![Group discussions](images/image9.jpg)
<hr>

![Workshop attendees](images/image10.jpg)

> In summary, the workshop delivered a thorough overview of AWS AI/ML services, spanning from traditional machine learning with SageMaker to next-generation Generative AI with Bedrock. The practical demonstrations and expert instruction made sophisticated concepts understandable and actionable. The main insight is that AWS has built a comprehensive ecosystem for developing, deploying, and scaling AI/ML applications, enabling faster and more efficient transformation of AI ideas into reality.
